<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="https://kinoshita.eti.br/feed.xml" rel="self" type="application/atom+xml" /><link href="https://kinoshita.eti.br/" rel="alternate" type="text/html" /><updated>2022-09-29T20:19:45+13:00</updated><id>https://kinoshita.eti.br/feed.xml</id><title type="html">kinow</title><subtitle>Bruno Kinoshita “kinow” personal home page</subtitle><entry><title type="html">Cyclic Workflows with Prefect</title><link href="https://kinoshita.eti.br/2021/11/08/cyclic-workflows-with-prefect.html" rel="alternate" type="text/html" title="Cyclic Workflows with Prefect" /><published>2021-11-08T00:00:00+13:00</published><updated>2021-11-08T00:00:00+13:00</updated><id>https://kinoshita.eti.br/2021/11/08/cyclic-workflows-with-prefect</id><content type="html" xml:base="https://kinoshita.eti.br/2021/11/08/cyclic-workflows-with-prefect.html">&lt;p&gt;&lt;img src=&quot;/assets/posts/2021-11-08-cyclic-workflows-with-prefect/prefect.svg&quot; alt=&quot;Prefect logo&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Last month I wrote about
&lt;a href=&quot;/2021/10/01/cyclic-workflows-with-cylc-and-stackstorm.html&quot;&gt;Cyclic Workflows with Cylc and StackStorm&lt;/a&gt;
and how few workflow managers support cyclic workflows.&lt;/p&gt;

&lt;p&gt;I was surprised today while reading Prefect documentation to see this paragraph:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Most workflow frameworks act as if looping is impossible (stressing the Acyclic part of the DAG),
but it’s actually trivial to implement. We simply dynamically unroll the loop, similar to how RNN
gradients are sometimes computed.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/2021-11-08-cyclic-workflows-with-prefect/Example-of-Unrolled-RNN-on-the-forward-pass.png&quot; alt=&quot;Example of Unrolled RNN on the forward-pass (image from https://machinelearningmastery.com/rnn-unrolling/)&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;small&gt;Image source: &lt;a href=&quot;https://machinelearningmastery.com/rnn-unrolling/&quot;&gt;A Gentle Introduction to RNN Unrolling
&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;The API for cyclic workflows of Prefect appears to be limited when compared with Cylc and
StackStorm, but they have a lot of integrations, and good documentation.&lt;/p&gt;

&lt;p&gt;I had to re-work the example from the previous post a bit, as using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;prep&lt;/code&gt; as entry point
resulted in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;prep&lt;/code&gt; present in every cycle. Their dependency and constraints algorithm is
probably re-executing the whole cycle, or there may be another way to have optional tasks
that I couldn’t find.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#!/bin/bash
# file: workflow.py
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;prefect&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;prefect&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;task&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Flow&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;prefect.engine.signals&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LOOP&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;INTERVAL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;


&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;task&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;prep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cycle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prefect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;task_loop_count&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prefect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;logger&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;INTERVAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;prep.&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cycle&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; says hi!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;task&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cycle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prefect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;task_loop_count&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cycle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;prep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prefect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;logger&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;INTERVAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;foo.&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cycle&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; says hi!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LOOP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;task&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;bar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cycle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prefect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;task_loop_count&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prefect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;logger&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;INTERVAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bar.&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cycle&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; says hi!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;hello-flow&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#flow.visualize() # need to pip install prefect['viz']
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Running the workflow is really simple (simpler than both
Cylc and StackStorm): &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;python workflow.py&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;venv&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; kinow@ranma:/tmp&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;python workflow.py 
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;2021-11-08 21:37:20+1300] INFO - prefect.FlowRunner | Beginning Flow run &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'hello-flow'&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;2021-11-08 21:37:20+1300] INFO - prefect.TaskRunner | Task &lt;span class=&quot;s1&quot;&gt;'foo'&lt;/span&gt;: Starting task run...
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;2021-11-08 21:37:21+1300] INFO - prefect.foo | prep.1 says hi!
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;2021-11-08 21:37:22+1300] INFO - prefect.foo | foo.1 says hi!
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;2021-11-08 21:37:23+1300] INFO - prefect.foo | bar.1 says hi!
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;2021-11-08 21:37:24+1300] INFO - prefect.foo | foo.2 says hi!
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;2021-11-08 21:37:25+1300] INFO - prefect.foo | bar.2 says hi!
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;2021-11-08 21:37:26+1300] INFO - prefect.foo | foo.3 says hi!
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;2021-11-08 21:37:27+1300] INFO - prefect.foo | bar.3 says hi!
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;2021-11-08 21:37:28+1300] INFO - prefect.foo | foo.4 says hi!
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;2021-11-08 21:37:29+1300] INFO - prefect.foo | bar.4 says hi!
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I had seen the RNN graph unrolling algorithm mentioned in their documentation
while working on &lt;a href=&quot;https://github.com/kinow/decyclify&quot;&gt;decyclify&lt;/a&gt;. I believe more
workflow managers will start supporting cyclic workflows soon. It adds some
complexity to the code, but so it does add dependency management, good logging,
configuration, distributed execution, and so on.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/2021-11-08-cyclic-workflows-with-prefect/graph-unroll.png&quot; alt=&quot;Decyclify algorithm (image from https://github.com/kinow/decyclify)&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I am not sure if the way I linked tasks is following best practices for Prefect. There
may be better ways so that Prefect can handle restarting workflows, for instance. But
if you want to run cyclic workflows, now you have —at least— three options.&lt;/p&gt;</content><author><name></name></author><category term="blog" /><category term="opensource" /><summary type="html">Last month I wrote about Cyclic Workflows with Cylc and StackStorm and how few workflow managers support cyclic workflows. I was surprised today while reading Prefect documentation to see this paragraph: Most workflow frameworks act as if looping is impossible (stressing the Acyclic part of the DAG), but it’s actually trivial to implement. We simply dynamically unroll the loop, similar to how RNN gradients are sometimes computed. Image source: A Gentle Introduction to RNN Unrolling The API for cyclic workflows of Prefect appears to be limited when compared with Cylc and StackStorm, but they have a lot of integrations, and good documentation. I had to re-work the example from the previous post a bit, as using prep as entry point resulted in prep present in every cycle. Their dependency and constraints algorithm is probably re-executing the whole cycle, or there may be another way to have optional tasks that I couldn’t find. #!/bin/bash # file: workflow.py import prefect from prefect import task, Flow from prefect.engine.signals import LOOP import time INTERVAL=1 @task def prep(): cycle = prefect.context.get(&quot;task_loop_count&quot;, 1) logger = prefect.context.get(&quot;logger&quot;) time.sleep(INTERVAL) logger.info(f&quot;prep.{cycle} says hi!&quot;) @task def foo(): cycle = prefect.context.get(&quot;task_loop_count&quot;, 1) if cycle == 1: prep.run() logger = prefect.context.get(&quot;logger&quot;) time.sleep(INTERVAL) logger.info(f&quot;foo.{cycle} says hi!&quot;) bar.run() raise LOOP() @task def bar(): cycle = prefect.context.get(&quot;task_loop_count&quot;, 1) logger = prefect.context.get(&quot;logger&quot;) time.sleep(INTERVAL) logger.info(f&quot;bar.{cycle} says hi!&quot;) with Flow(&quot;hello-flow&quot;) as flow: foo() flow.run() #flow.visualize() # need to pip install prefect['viz'] Running the workflow is really simple (simpler than both Cylc and StackStorm): python workflow.py (venv) kinow@ranma:/tmp$ python workflow.py [2021-11-08 21:37:20+1300] INFO - prefect.FlowRunner | Beginning Flow run for 'hello-flow' [2021-11-08 21:37:20+1300] INFO - prefect.TaskRunner | Task 'foo': Starting task run... [2021-11-08 21:37:21+1300] INFO - prefect.foo | prep.1 says hi! [2021-11-08 21:37:22+1300] INFO - prefect.foo | foo.1 says hi! [2021-11-08 21:37:23+1300] INFO - prefect.foo | bar.1 says hi! [2021-11-08 21:37:24+1300] INFO - prefect.foo | foo.2 says hi! [2021-11-08 21:37:25+1300] INFO - prefect.foo | bar.2 says hi! [2021-11-08 21:37:26+1300] INFO - prefect.foo | foo.3 says hi! [2021-11-08 21:37:27+1300] INFO - prefect.foo | bar.3 says hi! [2021-11-08 21:37:28+1300] INFO - prefect.foo | foo.4 says hi! [2021-11-08 21:37:29+1300] INFO - prefect.foo | bar.4 says hi! ... I had seen the RNN graph unrolling algorithm mentioned in their documentation while working on decyclify. I believe more workflow managers will start supporting cyclic workflows soon. It adds some complexity to the code, but so it does add dependency management, good logging, configuration, distributed execution, and so on. I am not sure if the way I linked tasks is following best practices for Prefect. There may be better ways so that Prefect can handle restarting workflows, for instance. But if you want to run cyclic workflows, now you have —at least— three options.</summary></entry><entry><title type="html">Removing invisible unread GitHub notifications</title><link href="https://kinoshita.eti.br/2021/10/22/removing-invisible-unread-github-notifications.html" rel="alternate" type="text/html" title="Removing invisible unread GitHub notifications" /><published>2021-10-22T00:00:00+13:00</published><updated>2021-10-22T00:00:00+13:00</updated><id>https://kinoshita.eti.br/2021/10/22/removing-invisible-unread-github-notifications</id><content type="html" xml:base="https://kinoshita.eti.br/2021/10/22/removing-invisible-unread-github-notifications.html">&lt;p&gt;&lt;img src=&quot;/assets/posts/2021-10-22-removing-invisible-unread-github-notifications/notifications.png&quot; alt=&quot;GitHub Notifications icon always-on mode&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Some months ago I noticed that even after I marked all my GitHub notifications
as read, the unread icon displayed at the right top corner was still showing as
if I had unread notifications.&lt;/p&gt;

&lt;p&gt;I tried changing the filters, waiting for a new notification to appear so that
I could mark it as read, all hoping that icon would then change. But no matter
what I tried in the GitHub UI, the icon was still there.&lt;/p&gt;

&lt;p&gt;Then I opened a ticket with GitHub support and within a couple of days they
replied suggesting me to use their
&lt;a href=&quot;https://docs.github.com/en/rest/reference/activity#mark-notifications-as-read&quot;&gt;REST API&lt;/a&gt;
to mark notifications as read.
So if you have the same issue, try the following
&lt;a href=&quot;https://github.com/kinow/dork-scripts/blob/master/github/mark-notifications-as-read.sh&quot;&gt;code&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# https://docs.github.com/en/rest/reference/activity#mark-notifications-as-read&lt;/span&gt;
curl &lt;span class=&quot;nt&quot;&gt;-X&lt;/span&gt; PUT &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Accept: application/vnd.github.v3+json&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Authorization: token &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TOKEN_GOES_HERE&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  https://api.github.com/notifications &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'{&quot;last_read_at&quot;: &quot;'&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'+%Y-%m-%dT%H:%M:%SZ'&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'&quot;}'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You will have to create a &lt;a href=&quot;https://github.com/settings/tokens&quot;&gt;token&lt;/a&gt; and use
it in the command above. Just give it “Notifications” permission, and delete
it after you have used it.&lt;/p&gt;</content><author><name></name></author><category term="blog" /><category term="opensource" /><summary type="html">Some months ago I noticed that even after I marked all my GitHub notifications as read, the unread icon displayed at the right top corner was still showing as if I had unread notifications. I tried changing the filters, waiting for a new notification to appear so that I could mark it as read, all hoping that icon would then change. But no matter what I tried in the GitHub UI, the icon was still there. Then I opened a ticket with GitHub support and within a couple of days they replied suggesting me to use their REST API to mark notifications as read. So if you have the same issue, try the following code: # https://docs.github.com/en/rest/reference/activity#mark-notifications-as-read curl -X PUT \ -H &quot;Accept: application/vnd.github.v3+json&quot; \ -H &quot;Authorization: token $TOKEN_GOES_HERE&quot; \ https://api.github.com/notifications -d '{&quot;last_read_at&quot;: &quot;'$(date '+%Y-%m-%dT%H:%M:%SZ')'&quot;}' You will have to create a token and use it in the command above. Just give it “Notifications” permission, and delete it after you have used it.</summary></entry><entry><title type="html">Blender rendering on NVIDIA Jetson Nano</title><link href="https://kinoshita.eti.br/2021/10/17/blender-rendering-on-nvidia-jetson-nano.html" rel="alternate" type="text/html" title="Blender rendering on NVIDIA Jetson Nano" /><published>2021-10-17T00:00:00+13:00</published><updated>2021-10-17T00:00:00+13:00</updated><id>https://kinoshita.eti.br/2021/10/17/blender-rendering-on-nvidia-jetson-nano</id><content type="html" xml:base="https://kinoshita.eti.br/2021/10/17/blender-rendering-on-nvidia-jetson-nano.html">&lt;p&gt;&lt;img src=&quot;/assets/posts/2021-10-17-blender-rendering-on-nvidia-jetson-nano/jetson.jpg&quot; alt=&quot;NVIDIA Jetson Nano computer&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I had used Blender during my graduation at the Mackenzie University and started learning
Blender 2.8+ again a few weeks ago. Unfortunately rendering the basic tutorials like Andrew
Price’s donut takes several minutes on my old (but excellent for programming) Thinkpad
T550 i7 16 GB with a simple Samsung SSD. The reason is that my GPU, a
&lt;a href=&quot;https://www.techpowerup.com/gpu-specs/nvs-5400m.c1742&quot;&gt;NVIDIA NVS 5400M&lt;/a&gt;
with 2 GB memory and 96 cores cannot be used with Blender as it only supports CUDA 2.1.
Blender 2.8+ GPU rendering requires CUDA 3.0 and higher, which means Blender Cycles
render is using my CPU, which is slower than using a decent GPU.&lt;/p&gt;

&lt;p&gt;Since I am really happy with my (refurbished) Thinkpad T550 and prefer to avoid buying
a new computer unless I really need to, my first idea was a GPU (egpu). These are simple
kits that allow you to connect a GPU to a notebook like mine using an adapter and some
port like thunderbolt, m.2 (removing wi-fi card), etc. But all these options are expensive
and the bandwidth is not near as good as using a GPU plugged in the motherboard.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/2021-10-17-blender-rendering-on-nvidia-jetson-nano/donut.png&quot; alt=&quot;Andrew Price (Blender Guru) donut&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A few months ago I heard about the &lt;a href=&quot;https://developer.nvidia.com/embedded/jetson-nano&quot;&gt;NVIDIA Jetson Nano&lt;/a&gt;
board computer. They are small board computers for embedded applications. Using an
ARM CPU and equipped with &lt;a href=&quot;https://www.techpowerup.com/gpu-specs/jetson-nano-gpu.c3643&quot;&gt;a GPU&lt;/a&gt;
with &lt;strong&gt;128 cores&lt;/strong&gt;. The computer has &lt;strong&gt;4 GB memory that is shared between the operating
system and the graphics processor&lt;/strong&gt;. And the NVIDIA Jetson Nano GPU supports CUDA 5.3,
which means it can be used by Blender to render scenes in the GPU.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/2021-10-17-blender-rendering-on-nvidia-jetson-nano/suzanne.png&quot; alt=&quot;A blender scene with Suzanne and modifiers&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;

&lt;p&gt;After following the Jetson Nano documentation to install it using an SD disk,
and enabling the performance overclock mode, I used &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;apt-get&lt;/code&gt; to install Blender.
The first thing I noticed is that it installed Blender 2.7. I tried downloading
2.8 since I had a few files created with this version, but then I realized I had
downloaded the x86_64 version. I couldn’t find 2.8 build for arm, so instead I
selected two files:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;One with Suzanne, the Blender monkey, configured with smaller tiles and added
a modifier to smooth it (I assumed that way it would use more of the GPU.)&lt;/li&gt;
  &lt;li&gt;The other one was the Blender 2.7 &lt;a href=&quot;https://www.blender.org/download/demo-files/&quot;&gt;splash screen&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I installed the same version of Blender, 2.7, on my Ubuntu Thinkpad, and configured the
tiles size on both files, and selected GPU rendering. Then I &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scp&lt;/code&gt;ed it to the NVIDIA
Jetson Nano Ubuntu, and set the render engine back to CPU on my Ubuntu.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/2021-10-17-blender-rendering-on-nvidia-jetson-nano/splashscreen.png&quot; alt=&quot;Blender 2.7 splash demo image&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;

&lt;p&gt;First I rendered Suzanne on my Thinkpad using the CPU. It took &lt;strong&gt;11 seconds to render&lt;/strong&gt;
the scene.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kinow@ranma:~/Downloads/blender&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;/opt/blender-2.79-linux-glibc219-x86_64/blender &lt;span class=&quot;nt&quot;&gt;-b&lt;/span&gt; b-jetson.blend &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; ./ &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; 1
found bundled python: /opt/blender-2.79-linux-glibc219-x86_64/2.79/python
Read blend: /home/kinow/Downloads/blender/b-jetson.blend
Fra:1 Mem:260.65M &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0.00M, Peak 525.85M&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; | Time:00:01.68 | Preparing Scene data
Fra:1 Mem:260.67M &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0.00M, Peak 525.85M&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; | Time:00:01.68 | Preparing Scene data
Fra:1 Mem:260.67M &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0.00M, Peak 525.85M&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; | Time:00:01.68 | Creating Shadowbuffers
Fra:1 Mem:260.67M &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0.00M, Peak 525.85M&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; | Time:00:01.68 | Raytree.. preparing
Fra:1 Mem:560.45M &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0.00M, Peak 560.45M&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; | Time:00:01.87 | Raytree.. building
&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;...&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
Fra:1 Mem:545.16M &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0.00M, Peak 1012.27M&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; | Time:00:11.36 | Scene, Part 82-135
Fra:1 Mem:544.70M &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0.00M, Peak 1012.27M&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; | Time:00:11.39 | Scene, Part 86-135
Fra:1 Mem:16.93M &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0.00M, Peak 1012.27M&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; | Time:00:11.43 | Sce: Scene Ve:2016578 Fa:2182948 La:1
Saved: &lt;span class=&quot;s1&quot;&gt;'./0001.png'&lt;/span&gt;
 Time: 00:11.49 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Saving: 00:00.06&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Tried the same command on my NVIDIA Jetson Nano now. It took &lt;strong&gt;48 seconds&lt;/strong&gt;. Near 4 times
longer than my old Thinkpad.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root@kinow-jetson:/home/kinow# blender &lt;span class=&quot;nt&quot;&gt;-b&lt;/span&gt; b-jetson.blend &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; ./ &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; 1
AL lib: &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;EE&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; UpdateDeviceParams: Failed to &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;44100hz, got 48000hz instead
Read blend: /home/kinow/b-jetson.blend
Fra:1 Mem:260.50M &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0.00M, Peak 525.70M&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; | Time:00:05.27 | Preparing Scene data
Fra:1 Mem:260.51M &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0.00M, Peak 525.70M&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; | Time:00:05.27 | Preparing Scene data
&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;...&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
Fra:1 Mem:594.15M &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0.00M, Peak 727.22M&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; | Time:00:48.26 | Scene, Part 86-135
Fra:1 Mem:16.78M &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0.00M, Peak 727.22M&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; | Time:00:48.36 | Sce: Scene Ve:2016578 Fa:2183144 La:1
Saved: &lt;span class=&quot;s1&quot;&gt;'./0001.png'&lt;/span&gt;
 Time: 00:48.53 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Saving: 00:00.17&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I thought it could be because my scene was too simple for the CPU to render,
so the GPU was being slower maybe due to the tile sizes or CPU&amp;lt;-&amp;gt;memory context
switching.&lt;/p&gt;

&lt;p&gt;So I tried the Splash screen now. &lt;strong&gt;01 hour and 53 minutes&lt;/strong&gt; on my Thinkpad.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Fra:1 Mem:2088.19M &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0.00M, Peak 4612.16M&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; | Time:01:53:53.18 | Sce: Scene Ve:0 Fa:0 La:0
Saved: &lt;span class=&quot;s1&quot;&gt;'./0001.png'&lt;/span&gt;
 Time: 01:53:54.08 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Saving: 00:00.90&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And on the NVIDIA Jetson Nano, &lt;strong&gt;22 hours and 38 minutes&lt;/strong&gt;.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Fra:1 Mem:2088.40M &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0.00M, Peak 4612.39M&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; | Time:22:38.00 | Sce: Scene Ve:0 Fa:0 La:0
Saved: &lt;span class=&quot;s1&quot;&gt;'./0001.png'&lt;/span&gt;
 Time: 22:38.22 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Saving: 00:00.21&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I did a few more experiments using the Suzanne file. Tried different command line
arguments, specifying the engine, number of threads, debug GPU to see if I could
see any warnings. But alas I could not find a setup that could speed up the process.&lt;/p&gt;

&lt;p&gt;Even tried a Python script I found in a forum to see this way the NVIDIA Jetson
Nano board would perform better.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;bpy&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enable_gpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;use_cpus&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;preferences&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;preferences&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cycles_preferences&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preferences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;addons&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cycles&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;preferences&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cuda_devices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opencl_devices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cycles_preferences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_devices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;CUDA&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;devices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cuda_devices&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;OPENCL&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;devices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opencl_devices&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;RuntimeError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Unsupported device type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;activated_gpus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;devices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;CPU&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;use&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;use_cpus&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;use&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;activated_gpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;cycles_preferences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compute_device_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device_type&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scene&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cycles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;GPU&quot;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activated_gpus&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;enable_gpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;CUDA&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The render was about the same time, a little slower, probably because Blender
needs to load and execute the Python script. After reading about users with
slow render times (not necessarily because of egpu or board computer GPU’s),
some users mentioned the kind of scene or file, and also the system memory.&lt;/p&gt;

&lt;p&gt;My old Thinkpad has 16 GB memory, where normally about 14 GB are free for Blender
to use while rendering. And even my old GPU, with its 2 GB dedicated memory would
probably perform about the same I guess with Blender, if it supported newer CUDA
versions (which means, if it also had a newer processor.)&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kinow@ranma:~&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;nvidia-smi 
Tue Sep 28 23:44:54 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 390.144                Driver Version: 390.144                   |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|&lt;span class=&quot;o&quot;&gt;===============================&lt;/span&gt;+&lt;span class=&quot;o&quot;&gt;======================&lt;/span&gt;+&lt;span class=&quot;o&quot;&gt;======================&lt;/span&gt;|
|   0  NVS 5400M           Off  | 00000000:01:00.0 N/A |                  N/A |
| N/A   56C    P0    N/A /  N/A |    294MiB /   964MiB |     N/A      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|&lt;span class=&quot;o&quot;&gt;=============================================================================&lt;/span&gt;|
|    0                    Not Supported                                       |
+-----------------------------------------------------------------------------+
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The NVIDIA Jetson Nano, with no GUI (I uninstalled &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ubuntu-desktop&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mousepad&lt;/code&gt;,
and disabled firewall and any other service that I considered unnecessary for Blender)
starts with ~600 MB of used memory, leaving 3.2 GB for Blender and for the GPU.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kinow@kinow-jetson:~&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;./mem
  mem free 3295.226562 MB mem total 3964.101562 MB mem used 668.875000 MB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;My guess is that while the NVIDIA Jetson Nano board works well for AI and IoT
applications that need the GPU for calculations that are not affected by the
shared memory, rendering 3D scenes in Blender would still perform better in
an egpu or in an environment with a new GPU.&lt;/p&gt;

&lt;p&gt;But at least I confirmed that you can render files in these board computers, and
it was a fun project. Things I am still thinking in trying someday:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Compile and try Blender 3.x for arm&lt;/li&gt;
  &lt;li&gt;Learn more about the Blender Python API and try to write some sort of debug function&lt;/li&gt;
  &lt;li&gt;Investigate if AI/machine learning applications have the same kind of problems (e.g.
&lt;a href=&quot;https://github.com/tensorflow/tensorflow/issues/39486&quot;&gt;see this tensorflow issue&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These boards are really fun, and support plugging cameras like the Raspberry Pi camera.
So it could be used for things like &lt;a href=&quot;https://techcrunch.com/2018/06/01/count-your-bees-with-this-raspberry-pi-project/&quot;&gt;counting number of bees&lt;/a&gt;,
or estimate the &lt;a href=&quot;https://www.youtube.com/watch?v=nUjGLjOmF7o&amp;amp;list=WL&amp;amp;index=14&quot;&gt;pose of a body&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;With dedicated memory for the graphics processor, it could probably perform a lot
better, but the CPU would also have to be improved a little, as well as the power
unit… and I suspect the cost would increase too. So not sure if at that point it
would not make more sense to buy an egpu or a dedicated workstation for Blender.&lt;/p&gt;

&lt;p&gt;For now, I am keeping my Thinkpad and will keep thinking how to improve my rendering
time.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Special thanks to Luke Reid for donating his NVIDIA Jetson Nano so I could test it
with Blender&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name></name></author><category term="blog" /><category term="opensource" /><category term="blender" /><summary type="html">I had used Blender during my graduation at the Mackenzie University and started learning Blender 2.8+ again a few weeks ago. Unfortunately rendering the basic tutorials like Andrew Price’s donut takes several minutes on my old (but excellent for programming) Thinkpad T550 i7 16 GB with a simple Samsung SSD. The reason is that my GPU, a NVIDIA NVS 5400M with 2 GB memory and 96 cores cannot be used with Blender as it only supports CUDA 2.1. Blender 2.8+ GPU rendering requires CUDA 3.0 and higher, which means Blender Cycles render is using my CPU, which is slower than using a decent GPU. Since I am really happy with my (refurbished) Thinkpad T550 and prefer to avoid buying a new computer unless I really need to, my first idea was a GPU (egpu). These are simple kits that allow you to connect a GPU to a notebook like mine using an adapter and some port like thunderbolt, m.2 (removing wi-fi card), etc. But all these options are expensive and the bandwidth is not near as good as using a GPU plugged in the motherboard. A few months ago I heard about the NVIDIA Jetson Nano board computer. They are small board computers for embedded applications. Using an ARM CPU and equipped with a GPU with 128 cores. The computer has 4 GB memory that is shared between the operating system and the graphics processor. And the NVIDIA Jetson Nano GPU supports CUDA 5.3, which means it can be used by Blender to render scenes in the GPU. After following the Jetson Nano documentation to install it using an SD disk, and enabling the performance overclock mode, I used apt-get to install Blender. The first thing I noticed is that it installed Blender 2.7. I tried downloading 2.8 since I had a few files created with this version, but then I realized I had downloaded the x86_64 version. I couldn’t find 2.8 build for arm, so instead I selected two files: One with Suzanne, the Blender monkey, configured with smaller tiles and added a modifier to smooth it (I assumed that way it would use more of the GPU.) The other one was the Blender 2.7 splash screen I installed the same version of Blender, 2.7, on my Ubuntu Thinkpad, and configured the tiles size on both files, and selected GPU rendering. Then I scped it to the NVIDIA Jetson Nano Ubuntu, and set the render engine back to CPU on my Ubuntu. First I rendered Suzanne on my Thinkpad using the CPU. It took 11 seconds to render the scene. kinow@ranma:~/Downloads/blender$ /opt/blender-2.79-linux-glibc219-x86_64/blender -b b-jetson.blend -o ./ -f 1 found bundled python: /opt/blender-2.79-linux-glibc219-x86_64/2.79/python Read blend: /home/kinow/Downloads/blender/b-jetson.blend Fra:1 Mem:260.65M (0.00M, Peak 525.85M) | Time:00:01.68 | Preparing Scene data Fra:1 Mem:260.67M (0.00M, Peak 525.85M) | Time:00:01.68 | Preparing Scene data Fra:1 Mem:260.67M (0.00M, Peak 525.85M) | Time:00:01.68 | Creating Shadowbuffers Fra:1 Mem:260.67M (0.00M, Peak 525.85M) | Time:00:01.68 | Raytree.. preparing Fra:1 Mem:560.45M (0.00M, Peak 560.45M) | Time:00:01.87 | Raytree.. building (...) Fra:1 Mem:545.16M (0.00M, Peak 1012.27M) | Time:00:11.36 | Scene, Part 82-135 Fra:1 Mem:544.70M (0.00M, Peak 1012.27M) | Time:00:11.39 | Scene, Part 86-135 Fra:1 Mem:16.93M (0.00M, Peak 1012.27M) | Time:00:11.43 | Sce: Scene Ve:2016578 Fa:2182948 La:1 Saved: './0001.png' Time: 00:11.49 (Saving: 00:00.06) Tried the same command on my NVIDIA Jetson Nano now. It took 48 seconds. Near 4 times longer than my old Thinkpad. root@kinow-jetson:/home/kinow# blender -b b-jetson.blend -o ./ -f 1 AL lib: (EE) UpdateDeviceParams: Failed to set 44100hz, got 48000hz instead Read blend: /home/kinow/b-jetson.blend Fra:1 Mem:260.50M (0.00M, Peak 525.70M) | Time:00:05.27 | Preparing Scene data Fra:1 Mem:260.51M (0.00M, Peak 525.70M) | Time:00:05.27 | Preparing Scene data (...) Fra:1 Mem:594.15M (0.00M, Peak 727.22M) | Time:00:48.26 | Scene, Part 86-135 Fra:1 Mem:16.78M (0.00M, Peak 727.22M) | Time:00:48.36 | Sce: Scene Ve:2016578 Fa:2183144 La:1 Saved: './0001.png' Time: 00:48.53 (Saving: 00:00.17) I thought it could be because my scene was too simple for the CPU to render, so the GPU was being slower maybe due to the tile sizes or CPU&amp;lt;-&amp;gt;memory context switching. So I tried the Splash screen now. 01 hour and 53 minutes on my Thinkpad. Fra:1 Mem:2088.19M (0.00M, Peak 4612.16M) | Time:01:53:53.18 | Sce: Scene Ve:0 Fa:0 La:0 Saved: './0001.png' Time: 01:53:54.08 (Saving: 00:00.90) And on the NVIDIA Jetson Nano, 22 hours and 38 minutes. Fra:1 Mem:2088.40M (0.00M, Peak 4612.39M) | Time:22:38.00 | Sce: Scene Ve:0 Fa:0 La:0 Saved: './0001.png' Time: 22:38.22 (Saving: 00:00.21) I did a few more experiments using the Suzanne file. Tried different command line arguments, specifying the engine, number of threads, debug GPU to see if I could see any warnings. But alas I could not find a setup that could speed up the process. Even tried a Python script I found in a forum to see this way the NVIDIA Jetson Nano board would perform better. import bpy def enable_gpus(device_type, use_cpus=False): preferences = bpy.context.preferences cycles_preferences = preferences.addons[&quot;cycles&quot;].preferences cuda_devices, opencl_devices = cycles_preferences.get_devices() if device_type == &quot;CUDA&quot;: devices = cuda_devices elif device_type == &quot;OPENCL&quot;: devices = opencl_devices else: raise RuntimeError(&quot;Unsupported device type&quot;) activated_gpus = [] for device in devices: if device.type == &quot;CPU&quot;: device.use = use_cpus else: device.use = True activated_gpus.append(device.name) cycles_preferences.compute_device_type = device_type bpy.context.scene.cycles.device = &quot;GPU&quot; return activated_gpus enable_gpus(&quot;CUDA&quot;) The render was about the same time, a little slower, probably because Blender needs to load and execute the Python script. After reading about users with slow render times (not necessarily because of egpu or board computer GPU’s), some users mentioned the kind of scene or file, and also the system memory. My old Thinkpad has 16 GB memory, where normally about 14 GB are free for Blender to use while rendering. And even my old GPU, with its 2 GB dedicated memory would probably perform about the same I guess with Blender, if it supported newer CUDA versions (which means, if it also had a newer processor.) kinow@ranma:~$ nvidia-smi Tue Sep 28 23:44:54 2021 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 390.144 Driver Version: 390.144 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 NVS 5400M Off | 00000000:01:00.0 N/A | N/A | | N/A 56C P0 N/A / N/A | 294MiB / 964MiB | N/A Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | 0 Not Supported | +-----------------------------------------------------------------------------+ The NVIDIA Jetson Nano, with no GUI (I uninstalled ubuntu-desktop, mousepad, and disabled firewall and any other service that I considered unnecessary for Blender) starts with ~600 MB of used memory, leaving 3.2 GB for Blender and for the GPU. kinow@kinow-jetson:~$ ./mem mem free 3295.226562 MB mem total 3964.101562 MB mem used 668.875000 MB My guess is that while the NVIDIA Jetson Nano board works well for AI and IoT applications that need the GPU for calculations that are not affected by the shared memory, rendering 3D scenes in Blender would still perform better in an egpu or in an environment with a new GPU. But at least I confirmed that you can render files in these board computers, and it was a fun project. Things I am still thinking in trying someday: Compile and try Blender 3.x for arm Learn more about the Blender Python API and try to write some sort of debug function Investigate if AI/machine learning applications have the same kind of problems (e.g. see this tensorflow issue) These boards are really fun, and support plugging cameras like the Raspberry Pi camera. So it could be used for things like counting number of bees, or estimate the pose of a body. With dedicated memory for the graphics processor, it could probably perform a lot better, but the CPU would also have to be improved a little, as well as the power unit… and I suspect the cost would increase too. So not sure if at that point it would not make more sense to buy an egpu or a dedicated workstation for Blender. For now, I am keeping my Thinkpad and will keep thinking how to improve my rendering time. Special thanks to Luke Reid for donating his NVIDIA Jetson Nano so I could test it with Blender</summary></entry><entry><title type="html">Cyclic Workflows with Cylc and StackStorm</title><link href="https://kinoshita.eti.br/2021/10/01/cyclic-workflows-with-cylc-and-stackstorm.html" rel="alternate" type="text/html" title="Cyclic Workflows with Cylc and StackStorm" /><published>2021-10-01T00:00:00+13:00</published><updated>2021-10-01T00:00:00+13:00</updated><id>https://kinoshita.eti.br/2021/10/01/cyclic-workflows-with-cylc-and-stackstorm</id><content type="html" xml:base="https://kinoshita.eti.br/2021/10/01/cyclic-workflows-with-cylc-and-stackstorm.html">&lt;p&gt;I am aware of only two workflow managers that support cyclic workflows.
&lt;a href=&quot;https://cylc.github.io/&quot;&gt;Cylc&lt;/a&gt; and &lt;a href=&quot;https://stackstorm.com/&quot;&gt;StackStorm&lt;/a&gt;. I won’t
enter into details about these two tools, but I must note that I worked on Cylc
during my employment with NIWA, in New Zealand.&lt;/p&gt;

&lt;p&gt;In this post I will only show a very simple workflow called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;five&lt;/code&gt; first using
Cylc, and then the same workflow with StackStorm.&lt;/p&gt;

&lt;h2 id=&quot;cylc&quot;&gt;Cylc&lt;/h2&gt;

&lt;p&gt;First let’s take a look at the source code of this workflow with Cylc 8 and plot it.&lt;/p&gt;

&lt;div class=&quot;language-ini highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nn&quot;&gt;[scheduling]&lt;/span&gt;
  &lt;span class=&quot;err&quot;&gt;cycling&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;mode&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;integer&lt;/span&gt;
  &lt;span class=&quot;err&quot;&gt;initial&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;cycle&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;point&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1&lt;/span&gt;
  &lt;span class=&quot;nn&quot;&gt;[[queues]&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;]&lt;/span&gt;
     &lt;span class=&quot;nn&quot;&gt;[[[default]&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;]]&lt;/span&gt;
       &lt;span class=&quot;py&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1&lt;/span&gt;
  &lt;span class=&quot;nn&quot;&gt;[[graph]&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;py&quot;&gt;R1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;prep =&amp;gt; foo&quot;&lt;/span&gt;
    &lt;span class=&quot;py&quot;&gt;P1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;foo[-P1] =&amp;gt; foo =&amp;gt; bar&quot;&lt;/span&gt;

&lt;span class=&quot;nn&quot;&gt;[runtime]&lt;/span&gt;
  &lt;span class=&quot;nn&quot;&gt;[[root]&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;py&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sleep 5&quot;&lt;/span&gt;
  &lt;span class=&quot;nn&quot;&gt;[[prep]&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;nn&quot;&gt;[[foo]&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;nn&quot;&gt;[[bar]&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The part &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;foo[-P1] =&amp;gt; foo =&amp;gt; bar&quot;&lt;/code&gt; is where the recursion occurs, creating
a cycle in the workflow.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/2021-10-01-cyclic-workflows-with-cylc-and-stackstorm/five-graph-cylc.png&quot; alt=&quot;workflow five plot - cylc&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Installing Cylc requires just &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pip install cylc-flow&lt;/code&gt;. After that, with the workflow
installed, we are ready to run it.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cylc &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; ~/cylc-src/five &lt;span class=&quot;nt&quot;&gt;--flow-name&lt;/span&gt; five
cylc play &lt;span class=&quot;nt&quot;&gt;--no-detach&lt;/span&gt; five/run1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The workflow will run forever, incrementing the cycle points, and triggering the tasks
in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;five&lt;/code&gt; workflow source. So you will have &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;foo.1&lt;/code&gt; (foo in the first cycle point),
that triggers both &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bar.1&lt;/code&gt; and also &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;foo.2&lt;/code&gt; (foo in the second cycle point) and so it
goes.&lt;/p&gt;

&lt;h2 id=&quot;stackstorm&quot;&gt;StackStorm&lt;/h2&gt;

&lt;p&gt;StackStorm requires more work to get everything up and running. Luckily they provide
a Docker Compose installation. So after the servers have been started with Docker
we are ready to create a “pack” (a neat way to organize separate installation files).&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; /opt/stackstorm/packs/kinow/
&lt;span class=&quot;nb&quot;&gt;touch&lt;/span&gt; /opt/stackstorm/packs/kinow/pack.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;name &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kinow&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kinow&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1.0.0&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;author&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kinow&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kinow@localhost&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And install the new pack.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;st2 pack &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;file:///opt/stackstorm/packs/kinow
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now we create a new workflow and an action to run the workflow — I think
this step is optional, and you could have just an action but I was following
one section of the docs that had it this way.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; /opt/stackstorm/packs/kinow/actions/workflows
&lt;span class=&quot;nb&quot;&gt;touch&lt;/span&gt; /opt/stackstorm/packs/kinow/actions/five.yaml
&lt;span class=&quot;nb&quot;&gt;touch&lt;/span&gt; /opt/stackstorm/packs/kinow/actions/workflows/five.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;five&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;pack&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kinow&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;five&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;runner_type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;orquesta&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;entry_point&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;workflows/five.yaml&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;enabled&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And now create the action in StackStorm, so we can run it via command line
or with the UI.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;st2 action create /opt/stackstorm/packs/kinow/actions/five.yaml 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And here’s the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;five&lt;/code&gt; workflow source for StackStorm, producing something very
similar (if no identical) to the graph produced by Cylc 8.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1.0&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;five&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;tasks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;prep&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;core.local cmd=&quot;sleep 5&quot;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;when&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;% succeeded() %&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;do&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;foo&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;core.local cmd=&quot;sleep 5&quot;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;when&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;% succeeded() %&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;do&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;foo&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;bar&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;bar&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;core.local cmd=&quot;sleep 5&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;foo&lt;/code&gt; is calling itself, creating a cycle in the workflow. And to run the
workflow:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;st2 run kinow.five
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The StackStorm UI does not appear to support showing the graph of the workflow
static or dynamically. But there is a community contributed UI called
&lt;a href=&quot;https://github.com/trstruth/rehearsal/&quot;&gt;rehearsal&lt;/a&gt; that plots an Orquesta
workflow given its source.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/2021-10-01-cyclic-workflows-with-cylc-and-stackstorm/five-graph-stackstorm-rehearsal.png&quot; alt=&quot;workflow five plot - stackstorm&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;final-notes&quot;&gt;Final notes&lt;/h2&gt;

&lt;p&gt;Both Cylc and StackStorm support Directed Cyclic Graphs in workflows, which is
really rare amongst workflow managers (or workflow standards, as I think WDL/CWL
also do not support cyclic workflows yet.)&lt;/p&gt;

&lt;p&gt;There are many pros and cons for each tool but that will have to be for a future
post. To finish this post here’s a screenshot of the StackStorm UI, followed by
one of the Cylc 8 UI. Both showing the workflow &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;five&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/2021-10-01-cyclic-workflows-with-cylc-and-stackstorm/stackstorm-ui.png&quot; alt=&quot;stackstorm ui&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/2021-10-01-cyclic-workflows-with-cylc-and-stackstorm/cylc-ui.png&quot; alt=&quot;stackstorm ui&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><category term="blog" /><category term="opensource" /><category term="cylc" /><summary type="html">I am aware of only two workflow managers that support cyclic workflows. Cylc and StackStorm. I won’t enter into details about these two tools, but I must note that I worked on Cylc during my employment with NIWA, in New Zealand. In this post I will only show a very simple workflow called five first using Cylc, and then the same workflow with StackStorm. Cylc First let’s take a look at the source code of this workflow with Cylc 8 and plot it. [scheduling] cycling mode = integer initial cycle point = 1 [[queues]] [[[default]]] limit = 1 [[graph]] R1 = &quot;prep =&amp;gt; foo&quot; P1 = &quot;foo[-P1] =&amp;gt; foo =&amp;gt; bar&quot; [runtime] [[root]] script=&quot;sleep 5&quot; [[prep]] [[foo]] [[bar]] The part &quot;foo[-P1] =&amp;gt; foo =&amp;gt; bar&quot; is where the recursion occurs, creating a cycle in the workflow. Installing Cylc requires just pip install cylc-flow. After that, with the workflow installed, we are ready to run it. cylc install -c ~/cylc-src/five --flow-name five cylc play --no-detach five/run1 The workflow will run forever, incrementing the cycle points, and triggering the tasks in the five workflow source. So you will have foo.1 (foo in the first cycle point), that triggers both bar.1 and also foo.2 (foo in the second cycle point) and so it goes. StackStorm StackStorm requires more work to get everything up and running. Luckily they provide a Docker Compose installation. So after the servers have been started with Docker we are ready to create a “pack” (a neat way to organize separate installation files). mkdir -p /opt/stackstorm/packs/kinow/ touch /opt/stackstorm/packs/kinow/pack.yaml --- name : kinow description: kinow version: 1.0.0 author: kinow email: kinow@localhost And install the new pack. st2 pack install file:///opt/stackstorm/packs/kinow Now we create a new workflow and an action to run the workflow — I think this step is optional, and you could have just an action but I was following one section of the docs that had it this way. mkdir -p /opt/stackstorm/packs/kinow/actions/workflows touch /opt/stackstorm/packs/kinow/actions/five.yaml touch /opt/stackstorm/packs/kinow/actions/workflows/five.yaml --- name: five pack: kinow description: five runner_type: orquesta entry_point: workflows/five.yaml enabled: true And now create the action in StackStorm, so we can run it via command line or with the UI. st2 action create /opt/stackstorm/packs/kinow/actions/five.yaml And here’s the five workflow source for StackStorm, producing something very similar (if no identical) to the graph produced by Cylc 8. version: 1.0 description: five tasks: prep: action: core.local cmd=&quot;sleep 5&quot; next: - when: &amp;lt;% succeeded() %&amp;gt; do: - foo foo: action: core.local cmd=&quot;sleep 5&quot; next: - when: &amp;lt;% succeeded() %&amp;gt; do: - foo - bar bar: action: core.local cmd=&quot;sleep 5&quot; Note that foo is calling itself, creating a cycle in the workflow. And to run the workflow: st2 run kinow.five The StackStorm UI does not appear to support showing the graph of the workflow static or dynamically. But there is a community contributed UI called rehearsal that plots an Orquesta workflow given its source. Final notes Both Cylc and StackStorm support Directed Cyclic Graphs in workflows, which is really rare amongst workflow managers (or workflow standards, as I think WDL/CWL also do not support cyclic workflows yet.) There are many pros and cons for each tool but that will have to be for a future post. To finish this post here’s a screenshot of the StackStorm UI, followed by one of the Cylc 8 UI. Both showing the workflow five.</summary></entry><entry><title type="html">Random traffic light</title><link href="https://kinoshita.eti.br/2021/04/06/random-traffic-light.html" rel="alternate" type="text/html" title="Random traffic light" /><published>2021-04-06T00:00:00+12:00</published><updated>2021-04-06T00:00:00+12:00</updated><id>https://kinoshita.eti.br/2021/04/06/random-traffic-light</id><content type="html" xml:base="https://kinoshita.eti.br/2021/04/06/random-traffic-light.html">&lt;p&gt;From a reference photo found &lt;a href=&quot;https://twitter.com/BlackLCult/status/1376896997647646720&quot;&gt;on Twitter&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pages/art/images/random-traffic-light.png&quot; alt=&quot;Gouache painting of a random traffic light&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/2021-04-06-random-traffic-light/ExroxZAWgAIQq1M.jpeg&quot; alt=&quot;Original photograph from Twitter&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><category term="painting" /><category term="painting" /><category term="gouache" /><category term="ink pen" /><summary type="html">From a reference photo found on Twitter.</summary></entry><entry><title type="html">Tufted Titmouse</title><link href="https://kinoshita.eti.br/2021/04/05/tufted-titmouse.html" rel="alternate" type="text/html" title="Tufted Titmouse" /><published>2021-04-05T00:00:00+12:00</published><updated>2021-04-05T00:00:00+12:00</updated><id>https://kinoshita.eti.br/2021/04/05/tufted-titmouse</id><content type="html" xml:base="https://kinoshita.eti.br/2021/04/05/tufted-titmouse.html">&lt;p&gt;From a reference photo by &lt;a href=&quot;https://twitter.com/ioannismou/status/1378365876878069761&quot;&gt;Ioannis Moutsatsos&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pages/art/images/tufted-titmouse.png&quot; alt=&quot;Drawing of a Tufted Titmouse on a fence&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/2021-04-05-tufted-titmouse/EyDv6GkXMAEF36-.jpeg&quot; alt=&quot;Original photograph of the Tufted Titmouse by Ioannis Moutsatsos&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Painted using recently learned techniques after watching a video
by &lt;a href=&quot;https://www.youtube.com/watch?v=ZrJrNGpl9-c&amp;amp;list=PLPXRG6jaep0VJfm_nuD-F_aifQLbkv34D&amp;amp;index=11&quot;&gt;Sarah Burns Studio&lt;/a&gt;,
and also other mixed media technique from a &lt;a href=&quot;https://www.domestika.org/en/courses/1434-pictorial-sketchbook-with-gouache/course&quot;&gt;Domestika course by Maru Godas&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><category term="painting" /><category term="painting" /><category term="gouache" /><category term="colored pencils" /><summary type="html">From a reference photo by Ioannis Moutsatsos. Painted using recently learned techniques after watching a video by Sarah Burns Studio, and also other mixed media technique from a Domestika course by Maru Godas.</summary></entry><entry><title type="html">Bezerra da Silva</title><link href="https://kinoshita.eti.br/2021/03/27/bezerra-da-silva.html" rel="alternate" type="text/html" title="Bezerra da Silva" /><published>2021-03-27T00:00:00+13:00</published><updated>2021-03-27T00:00:00+13:00</updated><id>https://kinoshita.eti.br/2021/03/27/bezerra-da-silva</id><content type="html" xml:base="https://kinoshita.eti.br/2021/03/27/bezerra-da-silva.html">&lt;p&gt;Created with Staedtler colored pencils, then digitalized and post-processed
in GIMP. Used a photo for reference.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pages/art/images/bezerra-03.png&quot; alt=&quot;Drawing of Bezerra da Silva&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/2021-03-27-bezerra-da-silva/bezerra-03-pre.png&quot; alt=&quot;Drawing of Bezerra da Silva in red colored pencil&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Used in Speak Like A Brazilian in &lt;a href=&quot;https://speaklikeabrazilian.com/blog/2019/09/21/brazilian-portuguese-expressions-in-songs-bezerra-da-silva-malandro-%C3%A9-malandro-e-man%C3%A9-%C3%A9-man%C3%A9.html&quot;&gt;this post&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/2021-03-27-bezerra-da-silva/Screen Shot 2021-03-30 at 15.31.32-fullpage.png&quot; alt=&quot;Drawing of Bezerra da Silva in Speak Like A Brazilian screenshot&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><category term="editorial illustration" /><summary type="html">Created with Staedtler colored pencils, then digitalized and post-processed in GIMP. Used a photo for reference. Used in Speak Like A Brazilian in this post.</summary></entry><entry><title type="html">Figurative drawing line of action 2021-03-11</title><link href="https://kinoshita.eti.br/2021/03/11/figurative-drawing-line-of-action-2021-03-11.html" rel="alternate" type="text/html" title="Figurative drawing line of action 2021-03-11" /><published>2021-03-11T00:00:00+13:00</published><updated>2021-03-11T00:00:00+13:00</updated><id>https://kinoshita.eti.br/2021/03/11/figurative-drawing-line-of-action-2021-03-11</id><content type="html" xml:base="https://kinoshita.eti.br/2021/03/11/figurative-drawing-line-of-action-2021-03-11.html">&lt;p&gt;&lt;img src=&quot;/assets/pages/art/images/255.png&quot; alt=&quot;Figurative drawing from Line of Action site&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><category term="drawing" /><summary type="html"></summary></entry><entry><title type="html">Low poly in Inkscape</title><link href="https://kinoshita.eti.br/2021/03/11/low-poly-in-inkscape.html" rel="alternate" type="text/html" title="Low poly in Inkscape" /><published>2021-03-11T00:00:00+13:00</published><updated>2021-03-11T00:00:00+13:00</updated><id>https://kinoshita.eti.br/2021/03/11/low-poly-in-inkscape</id><content type="html" xml:base="https://kinoshita.eti.br/2021/03/11/low-poly-in-inkscape.html">&lt;p&gt;The &lt;a href=&quot;https://inkscape.org/news/2021/01/23/about-screen-contest-inkscape-11-started/&quot;&gt;last Inkscape about screen contest&lt;/a&gt;
had two entries that called my attention for being created in Inkscape and for
how nice they looked. Not having used Inkscape for low poly before, I decided
to give it a try.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pages/art/images/low-poly-01.png&quot; alt=&quot;Low poly image&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;

&lt;p&gt;After reading a handful of tutorials, I realized it is a very interesting
and relaxing process. You use a reference photo with low opacity as background,
and then create the polygons manually with a vector pen.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pages/art/images/low-poly-02.png&quot; alt=&quot;Low poly image&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If I had to create many of these low poly images, I would probably automate it.
First looking for existing plug-ins or tools, or writing a simple script that
randomly creates the polygons based on a seed with some variance.&lt;/p&gt;

&lt;p&gt;The final result is very interesting for the eyes, creating an image that is easy
to “read” and can be used for social media and websites.&lt;/p&gt;</content><author><name></name></author><category term="digital illustration" /><category term="low poly" /><category term="inkscape" /><category term="vector art" /><category term="low poly" /><summary type="html">The last Inkscape about screen contest had two entries that called my attention for being created in Inkscape and for how nice they looked. Not having used Inkscape for low poly before, I decided to give it a try. After reading a handful of tutorials, I realized it is a very interesting and relaxing process. You use a reference photo with low opacity as background, and then create the polygons manually with a vector pen. If I had to create many of these low poly images, I would probably automate it. First looking for existing plug-ins or tools, or writing a simple script that randomly creates the polygons based on a seed with some variance. The final result is very interesting for the eyes, creating an image that is easy to “read” and can be used for social media and websites.</summary></entry><entry><title type="html">Yandê pães logo</title><link href="https://kinoshita.eti.br/2021/03/07/yande-paes-logo.html" rel="alternate" type="text/html" title="Yandê pães logo" /><published>2021-03-07T00:00:00+13:00</published><updated>2021-03-07T00:00:00+13:00</updated><id>https://kinoshita.eti.br/2021/03/07/yande-paes-logo</id><content type="html" xml:base="https://kinoshita.eti.br/2021/03/07/yande-paes-logo.html">&lt;p&gt;Logo created on Inkscape, based on ideas and sketches given by customer.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pages/art/images/yande-1.png&quot; alt=&quot;Yandê logo&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Used both for the store and for the social media and web sites.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pages/art/images/yande-2.jpg&quot; alt=&quot;Yandê logo&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pages/art/images/yande-3.png&quot; alt=&quot;Yandê logo&quot; class=&quot;center-aligned&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><category term="drawing" /><summary type="html">Logo created on Inkscape, based on ideas and sketches given by customer. Used both for the store and for the social media and web sites.</summary></entry></feed>