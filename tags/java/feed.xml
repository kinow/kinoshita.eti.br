<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Java on kinow</title><link>https://kinoshita.eti.br/tags/java.html</link><description>Recent content in Java on kinow</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Bruno P. Kinoshita All rights reserved</copyright><lastBuildDate>Wed, 21 May 2025 21:05:00 +0200</lastBuildDate><atom:link href="https://kinoshita.eti.br/tags/java/feed.xml" rel="self" type="application/rss+xml"/><item><title>Notes on Apache Jena StreamRDFWriter</title><link>https://kinoshita.eti.br/2020/04/11/notes-on-apache-jena-streamrdfwriter.html</link><pubDate>Sat, 11 Apr 2020 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2020/04/11/notes-on-apache-jena-streamrdfwriter.html</guid><description>&lt;p>&lt;a href="https://jena.apache.org/">Apache Jena&lt;/a> project is like a box full of interesting things—at least if you love programming. One of its many features, is &lt;strong>stream processing&lt;/strong>.&lt;/p>
&lt;p>The graphs in Jena may contain very large datasets, with giga- or terabytes. Some queries may be very large, and then sending the whole result would be simply impracticable.&lt;/p>
&lt;p>Instead, the data will go through ARQ. ARQ is a query engine for Jena that supports SPARQL. There is one piece of code there that I found interesting while reviewing a small pull request: &lt;a href="https://github.com/apache/jena/blob/cbdba5edb47041a4181a00bd7660e5d4c212530a/jena-arq/src/main/java/org/apache/jena/riot/system/StreamRDFWriter.java">&lt;code>org.apache.jena.riot.system.StreamRDFWriter&lt;/code>&lt;/a>.&lt;/p>
&lt;p>It is responsible for writing graph data in a streaming fashion. (See &lt;a href="https://en.wikipedia.org/wiki/Stream_processing">stream processing&lt;/a> for programming models and more.)&lt;/p>
&lt;h2 id="stream-factories">Stream factories&lt;/h2>
&lt;p>&lt;code>StreamRDFWriter&lt;/code> holds several implementations (as &lt;code>static&lt;/code> members) of &lt;code>StreamRDFWriterFactory&lt;/code>. The factory has one responsibility only, to create streams (&lt;code>StreamRDF&lt;/code>), for a certain format and context.&lt;/p>



&lt;figure class="feature">

 &lt;img
 src='https://kinoshita.eti.br/assets/posts/2020-04-11-notes-on-apache-jena-streamrdfwriter/01.png'
 alt=''
 title=''
 style=''
 width=''
 height=''
 />
 &lt;figcaption>&lt;/figcaption>

&lt;/figure></description></item><item><title>Use of Logging in Java Image Processing libraries</title><link>https://kinoshita.eti.br/2018/08/12/use-of-logging-in-java-image-processing-libraries.html</link><pubDate>Sun, 12 Aug 2018 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2018/08/12/use-of-logging-in-java-image-processing-libraries.html</guid><description>&lt;p>For &lt;a href="https://issues.apache.org/jira/browse/IMAGING-154">IMAGING-154&lt;/a> I was trying to think in a solution
for the &lt;a href="https://github.com/apache/commons-imaging/blob/d2ec76bd10f30c39ae5180ede1254908e76045f0/src/main/java/org/apache/commons/imaging/util/Debug.java">existing &lt;code>Debug&lt;/code>&lt;/a>
class. This class was the issue of discussion during a
&lt;a href="https://markmail.org/thread/ak3hcka7piykxixz#query:+page:1+mid:ppgxbhjx3opqlixj+state:results">previous 1.0 release vote thread&lt;/a>.&lt;/p></description></item><item><title>UUID's in Apache Jena</title><link>https://kinoshita.eti.br/2018/08/11/uuids-in-apache-jena.html</link><pubDate>Sat, 11 Aug 2018 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2018/08/11/uuids-in-apache-jena.html</guid><description>&lt;p>In this post I won&amp;rsquo;t talk about what are UUID&amp;rsquo;s, or how they work in Java.
&lt;a href="https://www.baeldung.com/java-uuid">Here&lt;/a>&amp;rsquo;s a great article on that. Or access the always reliable &lt;a href="https://en.wikipedia.org/wiki/Universally_unique_identifier">Wikipedia article&lt;/a>
about it. &lt;em>(or if you would rather, read the &lt;a href="http://www.ietf.org/rfc/rfc4122.txt">RFC 4122&lt;/a>)&lt;/em>&lt;/p>
&lt;p>I found out that Jena had UUID implementations after writing a
[previous post]({% post_url 2018-05-29-what-happens-when-you-create-a-new-dataset-in-apache-jena-fuseki %}).
And then decided to look into which UUID&amp;rsquo;s Jena has, and where these UUID&amp;rsquo;s
were used. This way I would either understand why Jena needed UUID&amp;rsquo;s, or
just be more educated in case I ever stumbled with a change in Jena that
required related work.&lt;/p></description></item><item><title>What happens when you create a new dataset in Apache Jena Fuseki</title><link>https://kinoshita.eti.br/2018/05/29/what-happens-when-you-create-a-new-dataset-in-apache-jena-fuseki.html</link><pubDate>Tue, 29 May 2018 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2018/05/29/what-happens-when-you-create-a-new-dataset-in-apache-jena-fuseki.html</guid><description>&lt;p>&lt;a href="{% post_url 2018-05-27-what-happens-when-you-upload-a-turtle-file-in-apache-jena-fuseki %}">Last post&lt;/a>
was about what happens when you upload a Turtle file to Apache Jena Fuseki. And now today&amp;rsquo;s post will be about
what happens when you create a new dataset in Apache Jena Fuseki.&lt;/p>
&lt;p>In theory, that happens before you upload a Turtle file, but this post series won&amp;rsquo;t follow a logical order.
It will be more based on what I find interesting.&lt;/p>
&lt;p>Oh, the dataset created is &lt;strong>an in-memory dataset&lt;/strong>. Here&amp;rsquo;s a simplified sequence diagram. Again,
these articles are more brain-dumps, used by myself for later reference.&lt;/p>



&lt;figure class="feature">

 &lt;img
 src='https://kinoshita.eti.br/assets/posts/2018-05-29-what-happens-when-you-create-a-new-dataset-in-apache-jena-fuseki/sequence-diagram.png'
 alt=''
 title=''
 style='display: inline; width: 100%;'
 width=''
 height=''
 />
 &lt;figcaption>&lt;/figcaption>

&lt;/figure></description></item><item><title>Learning more about SPARQL and Jena internals</title><link>https://kinoshita.eti.br/2018/04/28/learning-more-about-sparql-and-jena-internals.html</link><pubDate>Sat, 28 Apr 2018 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2018/04/28/learning-more-about-sparql-and-jena-internals.html</guid><description>O Corvo O Corvo Recently a pull request for Apache Jena that I started three years ago got merged. Even though it has been three years since that pull request, there are still many parts of the project code base that I am not familiar with.
And not only the code, but there are also many concepts about SPARQL, other standards used in Jena, and internals about triple stores.</description></item><item><title>Exif Odd Offsets</title><link>https://kinoshita.eti.br/2017/12/25/exif-odd-offsets.html</link><pubDate>Mon, 25 Dec 2017 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2017/12/25/exif-odd-offsets.html</guid><description>A file format like JPEG may contain metadata in JFIF, Exif, or a vendor proprietary format. The Exif format is based - or uses parts of - on the TIFF format.
Within an Exif metadata block, you should see directories, with several entries. The entries have fields like description, value, and also an offset. The offset indicates the offset to the next entry.
The Exif specification defines that implementers must make sure to keep the offset an even number, within 4 bytes.</description></item><item><title>Remember to synchronize when iterating streams from a synchronized Collection</title><link>https://kinoshita.eti.br/2017/12/03/remember-to-synchronize-when-iterating-streams-from-a-synchronized-collection.html</link><pubDate>Sun, 03 Dec 2017 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2017/12/03/remember-to-synchronize-when-iterating-streams-from-a-synchronized-collection.html</guid><description>When iterating collections created via Collections.synchronizedList for instance, you are required to obtain a lock on the actual list before doing so. So you normally end up with code similar to:
List list = Collections.synchronizedList(new ArrayList()); synchronized (list) { Iterator i = list.iterator(); // Must be in synchronized block while (i.hasNext()) foo(i.next()); } This requirement is documented in the javadocs.
Since lambdas and streams are being more widely used, it is important to remind that when iterating via a stream we also need to obtain a lock on the synchronized collection created.</description></item><item><title>Watch out for Locales when using NumberFormat with currencies</title><link>https://kinoshita.eti.br/2017/12/02/watch-out-for-locales-when-using-numberformat-with-currencies.html</link><pubDate>Sat, 02 Dec 2017 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2017/12/02/watch-out-for-locales-when-using-numberformat-with-currencies.html</guid><description>In Java you have the NumberFormatException to help you formatting and parsing numbers for any locale. Said that, here&amp;rsquo;s some code.
BigDecimal negative = new BigDecimal(&amp;#34;-1234.56&amp;#34;); DecimalFormat nf = (DecimalFormat) NumberFormat.getCurrencyInstance(Locale.UK); String formattedNegative = nf.format(negative); System.out.println(formattedNegative); The output for this code is -£1,234.56. That&amp;rsquo;s expected, as the locale is set to UK, so the currency symbol used is for British Pounds. And as the number is negative, you get that minus sign as a prefix.</description></item><item><title>Using formatter exclusions with Eclipse</title><link>https://kinoshita.eti.br/2017/11/06/using-formatter-exclusions-with-eclipse.html</link><pubDate>Mon, 06 Nov 2017 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2017/11/06/using-formatter-exclusions-with-eclipse.html</guid><description>Sometimes when you are formatting your code in Eclipse, you may want to prevent some parts of the code from being formatted. Especially when using Java 8 lambdas and optionals.
Here&amp;rsquo;s some code before being formatted by Eclipse&amp;rsquo;s default formatter rules.
Code adapted from: blog post Java d&amp;rsquo;eau ‐ Java 8: Streams in Hibernate and Beyond
session.createQuery(&amp;#34;SELECT h FROM Hare h&amp;#34;, Hare.class) .stream() .filter(h -&amp;gt; h.getId() == 1) .map(Hare::getName) .forEach(System.out::println); Then after formatting.</description></item><item><title>Finding Base64 implementations in Apache Software Foundation projects</title><link>https://kinoshita.eti.br/2017/09/01/finding-base64-implementations-in-apache-software-foundation-projects.html</link><pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2017/09/01/finding-base64-implementations-in-apache-software-foundation-projects.html</guid><description>NZ Grey Warbler (riroriro) New Zealand Grey Warbler (riroriro) Some time ago while working in one of the many projects in the Apache Software Foundation (Apache Commons FileUpload if I remember well), I noticed that it had a Base64 implementation. What called my attention was that the project not using the Apache Commons Codec Base64 implementation.
While Apache Commons&amp;rsquo; mission is to create components that can be re-used across ASF projects, and also by other projects not necessarily under the ASF, it is understandable that some projects prefer to keep its dependencies to a minimum.</description></item><item><title>Two other Maven Plug-ins: impsort and deptools</title><link>https://kinoshita.eti.br/2017/08/12/two-other-maven-plug-ins-impsort-and-deptools.html</link><pubDate>Sat, 12 Aug 2017 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2017/08/12/two-other-maven-plug-ins-impsort-and-deptools.html</guid><description>Last [week I wrote]({% post_url 2017-08-06-checking-for-transitive-dependencies-use-with-maven-enforcer-plugin %}) about the ImmobilienScout24/illegal-transitive-dependency-check rule for Maven Enforcer Plug-in. There are two other Maven Plug-ins that can be useful.
mbknor/deptools The mbknor/deptools is another rule for the Maven Enforcer Plug-in. It will scan your project dependency tree, looking for transitive dependencies. Whenever it finds a transitive dependency, it will keep track of the versions. And if, because of the way your dependencies and transitive dependencies are organised, you end up with a version that is not the newest, the build will fail.</description></item><item><title>Checking for transitive dependencies use with Maven Enforcer Plug-in</title><link>https://kinoshita.eti.br/2017/08/06/checking-for-transitive-dependencies-use-with-maven-enforcer-plug-in.html</link><pubDate>Sun, 06 Aug 2017 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2017/08/06/checking-for-transitive-dependencies-use-with-maven-enforcer-plug-in.html</guid><description>Maven Enforcer Plug-in “provides goals to control certain environmental constraints such as Maven version, JDK version and OS family along with many more built-in rules and user created rules”. There are several libraries that provide custom rules, or you can write your own.
One of these libraries is ImmobilienScout24/illegal-transitive-dependency-check, “an additional rule for the maven-enforcer-plugin that checks for classes referenced via transitive Maven dependencies”.
With the following example:
&amp;lt;project&amp;gt; ... &amp;lt;build&amp;gt; &amp;lt;plugins&amp;gt; &amp;lt;plugin&amp;gt; &amp;lt;groupId&amp;gt;org.</description></item><item><title>Backward compatibility and switch statement with constant expressions</title><link>https://kinoshita.eti.br/2017/06/10/backward-compatibility-and-switch-statement-with-constant-expressions.html</link><pubDate>Sat, 10 Jun 2017 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2017/06/10/backward-compatibility-and-switch-statement-with-constant-expressions.html</guid><description>Maintaining Open Source software can be challenging. Making sure you keep backward compatibility (not only binary) can be even more challenging. Apache Commons Lang 3.6 release is happening right now thanks to Benedikt Ritter, and it is on its fourth Release Candidate (i.e. RC4).
A previous RC2 was cancelled due to IBM JDK 8 compatibility, more specifically the lazy initialization of ArrayList&amp;rsquo;s seems to be different in Oracle JDK and IBM JDK.</description></item><item><title>Apache Commons Text LookupTranslator</title><link>https://kinoshita.eti.br/2017/06/02/apache-commons-text-lookuptranslator.html</link><pubDate>Fri, 02 Jun 2017 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2017/06/02/apache-commons-text-lookuptranslator.html</guid><description>Apache Commons Text includes several algorithms for text processing. Today&amp;rsquo;s post is about one of the classes available since the 1.0 release, the LookupTranslator.
It is used to translate text using a lookup table. Most users won&amp;rsquo;t necessarily be - knowingly - using this class. Most likely, they will use the StringEscapeUtils, which contains methods to escape and unescape CSV, JSON, XML, Java, and EcmaScript.
String original = &amp;#34;He didn&amp;#39;t say, \&amp;#34;stop!</description></item><item><title>Some links related to Apache Commons Text</title><link>https://kinoshita.eti.br/2017/05/28/some-links-related-to-apache-commons-text.html</link><pubDate>Sun, 28 May 2017 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2017/05/28/some-links-related-to-apache-commons-text.html</guid><description>Apache Commons Text is one of the most recent new components in Apache Commons. It &amp;ldquo;is a library focused on algorithms working on strings&amp;rdquo;. I recently collected some links under a bookmark folder that are in some way related to the project. In case you are interested, check some of the links below.
Morgan Wahl Text is More Complicated Than You Think Comparing and Sorting Unicode PyCon 2017 Q: test [text] to check if our methods are OK with some examples in this talk) Q: Canonical Decomposition, and code points comparisons; are we doing it?</description></item><item><title>When you don't realize you need a Comparable</title><link>https://kinoshita.eti.br/2017/05/15/when-you-dont-realize-you-need-a-comparable.html</link><pubDate>Mon, 15 May 2017 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2017/05/15/when-you-dont-realize-you-need-a-comparable.html</guid><description>&lt;p>[In 2012, I wrote]({% post_url 2012-10-20-replacing-a-hashset-with-a-bitset %}) about how you always learn something
new by following the &lt;a href="http://www.apache.org/foundation/mailinglists.html">Apache dev mailing lists&lt;/a>.&lt;/p>
&lt;p>After about five years, I am still learning, and still getting impressed by the knowledge of other
developers. Days ago I was massaging some code in &lt;a href="https://github.com/apache/jena/pull/237">a pull request&lt;/a>
and a developer suggested me to simplify my code.&lt;/p></description></item><item><title>Troubleshooting a Jenkins Plug-in compatibility issue</title><link>https://kinoshita.eti.br/2017/04/17/troubleshooting-a-jenkins-plug-in-compatibility-issue.html</link><pubDate>Mon, 17 Apr 2017 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2017/04/17/troubleshooting-a-jenkins-plug-in-compatibility-issue.html</guid><description>This post is probably different from others. I will give a TL;DR, but will then give you a copy of a comment of a Jenkins JIRA issue. Hope you have fun reading it, specially if you maintain Jenkins servers or plug-ins.
TL;DR: there was an issue in Jenkins Job DSL Plug-in, that caused jobs created to have an invalid script. The fix had not been released, but was already in the master branch in GitHub.</description></item><item><title>Spring Cloud encrypted values and Spring PropertySources</title><link>https://kinoshita.eti.br/2017/04/14/spring-cloud-encrypted-values-and-spring-propertysources.html</link><pubDate>Fri, 14 Apr 2017 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2017/04/14/spring-cloud-encrypted-values-and-spring-propertysources.html</guid><description>As I could not find any documentation for that, I decided to write it as a note to myself in case I use the encryption and decryption with Spring Cloud again.
In Spring and Spring Boot, you normally have multiple sources of properties, like multiple properties files, environment properties and variables, and so it goes. In the Spring API, these are represented as PropertySource&amp;rsquo;s.
In a Spring Boot application, you would be used to overriding certain properties by defining environments and using an application-production.</description></item><item><title>Apache Commons Lang: Memoizer</title><link>https://kinoshita.eti.br/2017/01/08/apache-commons-lang-memoizer.html</link><pubDate>Sun, 08 Jan 2017 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2017/01/08/apache-commons-lang-memoizer.html</guid><description>The current release of Apache Commons Lang is 3.5. The upcoming release, probably 3.6, will include a new feature, added in a pull request: a Memoizer implementation. Check out the ticket LANG-740 for more about the implementation being added to [lang].
The book Java Concurrency in Practice introduces readers to the Memoizer, and has also a public domain implementation available for download (besides that, the book has also lots of other interesting topics!</description></item><item><title>Apache Commons Text</title><link>https://kinoshita.eti.br/2017/01/07/apache-commons-text.html</link><pubDate>Sat, 07 Jan 2017 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2017/01/07/apache-commons-text.html</guid><description>There is a new component in Apache Commons: Apache Commons Text. The 1.0 release might be announced in the next weeks. The current site is still in the Commons Sandbox, but it will change with the 1.0 release. The promotion from the sandbox happened a few days ago in the project mailing list.
Here&amp;rsquo;s the project description: Apache Commons Text is a library focused on algorithms working on strings.
There was a thread on the mailing list some time ago (Oct/2014) when we first discussed the component idea.</description></item></channel></rss>