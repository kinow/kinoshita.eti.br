<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Big Data on kinow</title><link>https://kinoshita.eti.br/tags/big-data.html</link><description>Recent content in Big Data on kinow</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Bruno P. Kinoshita All rights reserved</copyright><lastBuildDate>Sun, 15 Dec 2024 12:46:07 +0100</lastBuildDate><atom:link href="https://kinoshita.eti.br/tags/big-data/feed.xml" rel="self" type="application/rss+xml"/><item><title>Running word-count example on a Hadoop commodity-hardware cluster and on a Hadoop local installation</title><link>https://kinoshita.eti.br/2012/09/20/running-word-count-example-on-a-hadoop-commodity-hardware-cluster-and-on-a-hadoop-local-installation.html</link><pubDate>Thu, 20 Sep 2012 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2012/09/20/running-word-count-example-on-a-hadoop-commodity-hardware-cluster-and-on-a-hadoop-local-installation.html</guid><description>&lt;p>Last weekend I spent some hours assembling old computer parts to create my commodity hardware cluster for running Hadoop. I already had a local installation in my notebook, so I thought it would be cool to run the word-count example in both scenarios to see what would be the results.&lt;/p>
&lt;p>But first, let's review the hardware configurations:&lt;/p></description></item></channel></rss>