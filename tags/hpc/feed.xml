<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Hpc on kinow</title><link>https://kinoshita.eti.br/tags/hpc.html</link><description>Recent content in Hpc on kinow</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Bruno P. Kinoshita All rights reserved</copyright><lastBuildDate>Wed, 05 Feb 2025 17:05:05 +0100</lastBuildDate><atom:link href="https://kinoshita.eti.br/tags/hpc/feed.xml" rel="self" type="application/rss+xml"/><item><title>Running Cylc tasks on PBS Torque with Docker</title><link>https://kinoshita.eti.br/2018/12/22/running-cylc-tasks-on-pbs-torque-with-docker.html</link><pubDate>Sat, 22 Dec 2018 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2018/12/22/running-cylc-tasks-on-pbs-torque-with-docker.html</guid><description>&lt;p>A few days ago I saw &lt;a href="https://groups.google.com/forum/#!topic/cylc/dP2I1Gxqi20">a post&lt;/a> at the
Cylc Google Group, about file permissions for files generated by Cylc. The post was related to
content created by Cylc, but in an environment with PBS.&lt;/p>
&lt;p>For context, Cylc is an Open Source meta-scheduler, written in Python, that allows you to
define cycle points with dependencies. These cycle points can be simple incremental integer
numbers, or ISO8601 periods or points (e.g. run every 5 minutes, from 10 days ago until the
next year). Cylc takes care to create an execution schedule for you, and delegate that to a
system that runs your workflow. I work full time on this amazing Open Source tool!&lt;/p>
&lt;p>Such system could be the local computer in background, batch systems such as &lt;code>at&lt;/code>, or PBS.
PBS was created for NASA, to manage executing jobs taking into consideration cluster resources,
and also using queues, priorities, and other features useful for HPC programming. Later PBS
was acquired by Altair, an Open Source version OpenPBS was created, and later abandoned. And
there is another fork called PBS Torque. I first encountered PBS at the SÃ£o Paulo
University, in Brazil, where they had a &lt;a href="http://www.usp.br/hpc/puma.php">PBS Torque cluster&lt;/a>.&lt;/p>
&lt;h3 id="running-pbs-torque-with-docker">Running PBS Torque with Docker&lt;/h3>
&lt;p>Even though I have access to an environment with Cylc and with PBS, I decided to give it a try
and see how hard it would be to reproduce it with Docker. One thing that I like about this
approach is the possibility to share the work with others online. I believe it improves
communication, agility, and can be useful for posterity.&lt;/p></description></item><item><title>Reading notes about DRMAA v2</title><link>https://kinoshita.eti.br/2016/07/20/reading-notes-about-drmaa-v2.html</link><pubDate>Wed, 20 Jul 2016 00:00:00 +0000</pubDate><guid>https://kinoshita.eti.br/2016/07/20/reading-notes-about-drmaa-v2.html</guid><description>&lt;p>The DRMAA v2 specification draft is ready to be published, and is in &lt;a href="https://redmine.ogf.org/boards/36/topics/494">public
comment&lt;/a> until 31st July this year.
I used DRMAA v1 to integrate Jenkins and PBS some time ago, but it was not a
very elegant solution.&lt;/p>
&lt;p>And in the end integrating other grid computing implementations like SGE would
not be very simple.&lt;/p>
&lt;p>This post contains my reading notes for DRMAA v2, and a short analysis of how
this new specification could be used in a new tentative to integrate
Jenkins and several grid computing implementations in a single plug-in.&lt;/p></description></item></channel></rss>