<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Some Linux commands I used this week | kinow</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Some Linux commands I used this week" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="These are some commands I used on Linux servers this week. Adding them here in case someone else find them interesting, and also due to my bad memory :-) Listing latest installed packages in SLES rpm -qa --last This will display the last packages installed. Useful when there are packages being updated, and you need to confirm what changed, and when. Listing packages in SLES and origin repository rpm -qa --qf &#39;%-30{DISTRIBUTION} %{NAME}\n&#39;| sort The output will have two columns. The first containing the repository name, and the second column with the package name. For example. devel:languages:R:base / SLE_11_SP2 R-base devel:languages:R:base / SLE_11_SP2 R-base-devel home:flacco:sles / SLE_11_SP3 php53-phar home:happenpappen / SLE_11_SP2 nodejs Grep for content in XML tags Be it for web services, or for finding things in Jenkins XML files. Being able to grep the tag attribute or tag name might be useful. Look at the following example that uses the books XML provided by Microsoft for testing. grep -oP &quot;(?&lt;=&lt;genre&gt;).*?(?=&lt;/genre&gt;)&quot; books.xml | sort | uniq Which will outputs the following. Computer Fantasy Horror Romance Science Fiction Find Python site packages directory Sometimes you have Anaconda, but also the system installation, and maybe even other Python distributions. Knowing where Python is looking for site packages can be helpful to confirm the package exists, and also to inspect its sources. python -c &quot;from distutils.sysconfig import get_python_lib; print(get_python_lib())&quot; An example of the output of the script. /usr/lib/python2.7/dist-packages Force no-cache via curl for a list of files Useful when you have a proxy like squid caching some requests from an application and you want to flush the cache and get the latest content (which will be cached again, but then you can fix it once confirmed). curl --silent -H &#39;Cache-Control: no-cache&#39; http://systemcachingvalues.local/somedoc.html Find to which servers a Linux process is talking to You have to find the pid of the process that you would like to investigate (e.g. 6364) and have strace installed. strace -p 6364 -f -e trace=network -o output.txt The command above creates output.txt with the trace information. Then you can grep for the IP addresses with the following regex. grep -E -o &quot;(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)&quot; output.txt Which will output something similar to the following example. 127.0.1.1 127.0.1.1 127.0.1.1 192.168.20.4 10.10.0.12 ... And finally, you can call dig to get the server name, and also remove duplicates. grep -E -o &quot;(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)&quot; output.txt | xargs -l dig +noall +answer +nocmd -x | awk &#39;{ print $5}&#39; | sort | uniq Which gives you the following. ec2-52-13-43-205.compute-1.amazonaws.com. ec2-52-32-244-147.compute-1.amazonaws.com. ec2-52-44-11-85.compute-1.amazonaws.com. ec2-52-55-36-20.us-west-2.compute.amazonaws.com. ec2-52-11-19-24.us-west-2.compute.amazonaws.com. ec2-52-2-21-13.compute-1.amazonaws.com. ec2-54-33-249-49.us-west-2.compute.amazonaws.com. ec2-54-180-165-17.us-west-2.compute.amazonaws.com. ec2-54-2-177-91.compute-1.amazonaws.com. ec2-54-8-163-15.compute-1.amazonaws.com. syd11s01-in-f124.1e110.net. syd11s02-in-f5.1e110.net. syd12s02-in-f3.1e110.net. ... That’s all for today. Happy hacking!" />
<meta property="og:description" content="These are some commands I used on Linux servers this week. Adding them here in case someone else find them interesting, and also due to my bad memory :-) Listing latest installed packages in SLES rpm -qa --last This will display the last packages installed. Useful when there are packages being updated, and you need to confirm what changed, and when. Listing packages in SLES and origin repository rpm -qa --qf &#39;%-30{DISTRIBUTION} %{NAME}\n&#39;| sort The output will have two columns. The first containing the repository name, and the second column with the package name. For example. devel:languages:R:base / SLE_11_SP2 R-base devel:languages:R:base / SLE_11_SP2 R-base-devel home:flacco:sles / SLE_11_SP3 php53-phar home:happenpappen / SLE_11_SP2 nodejs Grep for content in XML tags Be it for web services, or for finding things in Jenkins XML files. Being able to grep the tag attribute or tag name might be useful. Look at the following example that uses the books XML provided by Microsoft for testing. grep -oP &quot;(?&lt;=&lt;genre&gt;).*?(?=&lt;/genre&gt;)&quot; books.xml | sort | uniq Which will outputs the following. Computer Fantasy Horror Romance Science Fiction Find Python site packages directory Sometimes you have Anaconda, but also the system installation, and maybe even other Python distributions. Knowing where Python is looking for site packages can be helpful to confirm the package exists, and also to inspect its sources. python -c &quot;from distutils.sysconfig import get_python_lib; print(get_python_lib())&quot; An example of the output of the script. /usr/lib/python2.7/dist-packages Force no-cache via curl for a list of files Useful when you have a proxy like squid caching some requests from an application and you want to flush the cache and get the latest content (which will be cached again, but then you can fix it once confirmed). curl --silent -H &#39;Cache-Control: no-cache&#39; http://systemcachingvalues.local/somedoc.html Find to which servers a Linux process is talking to You have to find the pid of the process that you would like to investigate (e.g. 6364) and have strace installed. strace -p 6364 -f -e trace=network -o output.txt The command above creates output.txt with the trace information. Then you can grep for the IP addresses with the following regex. grep -E -o &quot;(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)&quot; output.txt Which will output something similar to the following example. 127.0.1.1 127.0.1.1 127.0.1.1 192.168.20.4 10.10.0.12 ... And finally, you can call dig to get the server name, and also remove duplicates. grep -E -o &quot;(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)&quot; output.txt | xargs -l dig +noall +answer +nocmd -x | awk &#39;{ print $5}&#39; | sort | uniq Which gives you the following. ec2-52-13-43-205.compute-1.amazonaws.com. ec2-52-32-244-147.compute-1.amazonaws.com. ec2-52-44-11-85.compute-1.amazonaws.com. ec2-52-55-36-20.us-west-2.compute.amazonaws.com. ec2-52-11-19-24.us-west-2.compute.amazonaws.com. ec2-52-2-21-13.compute-1.amazonaws.com. ec2-54-33-249-49.us-west-2.compute.amazonaws.com. ec2-54-180-165-17.us-west-2.compute.amazonaws.com. ec2-54-2-177-91.compute-1.amazonaws.com. ec2-54-8-163-15.compute-1.amazonaws.com. syd11s01-in-f124.1e110.net. syd11s02-in-f5.1e110.net. syd12s02-in-f3.1e110.net. ... That’s all for today. Happy hacking!" />
<link rel="canonical" href="https://kinoshita.eti.br/2016/05/06/some-linux-commands-i-used-this-week.html" />
<meta property="og:url" content="https://kinoshita.eti.br/2016/05/06/some-linux-commands-i-used-this-week.html" />
<meta property="og:site_name" content="kinow" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2016-05-06T00:00:00+12:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Some Linux commands I used this week" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kinoshita.eti.br/2016/05/06/some-linux-commands-i-used-this-week.html"},"description":"These are some commands I used on Linux servers this week. Adding them here in case someone else find them interesting, and also due to my bad memory :-) Listing latest installed packages in SLES rpm -qa --last This will display the last packages installed. Useful when there are packages being updated, and you need to confirm what changed, and when. Listing packages in SLES and origin repository rpm -qa --qf &#39;%-30{DISTRIBUTION} %{NAME}\\n&#39;| sort The output will have two columns. The first containing the repository name, and the second column with the package name. For example. devel:languages:R:base / SLE_11_SP2 R-base devel:languages:R:base / SLE_11_SP2 R-base-devel home:flacco:sles / SLE_11_SP3 php53-phar home:happenpappen / SLE_11_SP2 nodejs Grep for content in XML tags Be it for web services, or for finding things in Jenkins XML files. Being able to grep the tag attribute or tag name might be useful. Look at the following example that uses the books XML provided by Microsoft for testing. grep -oP &quot;(?&lt;=&lt;genre&gt;).*?(?=&lt;/genre&gt;)&quot; books.xml | sort | uniq Which will outputs the following. Computer Fantasy Horror Romance Science Fiction Find Python site packages directory Sometimes you have Anaconda, but also the system installation, and maybe even other Python distributions. Knowing where Python is looking for site packages can be helpful to confirm the package exists, and also to inspect its sources. python -c &quot;from distutils.sysconfig import get_python_lib; print(get_python_lib())&quot; An example of the output of the script. /usr/lib/python2.7/dist-packages Force no-cache via curl for a list of files Useful when you have a proxy like squid caching some requests from an application and you want to flush the cache and get the latest content (which will be cached again, but then you can fix it once confirmed). curl --silent -H &#39;Cache-Control: no-cache&#39; http://systemcachingvalues.local/somedoc.html Find to which servers a Linux process is talking to You have to find the pid of the process that you would like to investigate (e.g. 6364) and have strace installed. strace -p 6364 -f -e trace=network -o output.txt The command above creates output.txt with the trace information. Then you can grep for the IP addresses with the following regex. grep -E -o &quot;(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)&quot; output.txt Which will output something similar to the following example. 127.0.1.1 127.0.1.1 127.0.1.1 192.168.20.4 10.10.0.12 ... And finally, you can call dig to get the server name, and also remove duplicates. grep -E -o &quot;(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)&quot; output.txt | xargs -l dig +noall +answer +nocmd -x | awk &#39;{ print $5}&#39; | sort | uniq Which gives you the following. ec2-52-13-43-205.compute-1.amazonaws.com. ec2-52-32-244-147.compute-1.amazonaws.com. ec2-52-44-11-85.compute-1.amazonaws.com. ec2-52-55-36-20.us-west-2.compute.amazonaws.com. ec2-52-11-19-24.us-west-2.compute.amazonaws.com. ec2-52-2-21-13.compute-1.amazonaws.com. ec2-54-33-249-49.us-west-2.compute.amazonaws.com. ec2-54-180-165-17.us-west-2.compute.amazonaws.com. ec2-54-2-177-91.compute-1.amazonaws.com. ec2-54-8-163-15.compute-1.amazonaws.com. syd11s01-in-f124.1e110.net. syd11s02-in-f5.1e110.net. syd12s02-in-f3.1e110.net. ... That’s all for today. Happy hacking!","@type":"BlogPosting","url":"https://kinoshita.eti.br/2016/05/06/some-linux-commands-i-used-this-week.html","headline":"Some Linux commands I used this week","dateModified":"2016-05-06T00:00:00+12:00","datePublished":"2016-05-06T00:00:00+12:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/main.css"><link type="application/atom+xml" rel="alternate" href="https://kinoshita.eti.br/feed.xml" title="kinow" /><link href="https://unpkg.com/pattern.css" rel="stylesheet">

</head>
<body>
<div id="mobile-menu"><div class="menu">
  <ul class="menu">
    <li class="item">
      <h1 id="kinow">KINOW</h1>
    </li>
    <li class="item">
      <a href="/" class="">About</a>
    </li>
    <li class="item">
      <a href="/blog/" class="current">Blog</a>
    </li>
    <li class="item">
      <a href="/portfolio/" class="">Portfolio</a>
    </li>
    <li class="item social-media-item">
      <a href="https://www.instagram.com/brunokinoshita/" class="inline-link">
        <img src="/assets/icons/instagram.png" class="inverted-image" />
      </a>
      <a href="https://twitter.com/kinow/" class="inline-link">
        <img src="/assets/icons/twitter.png" class="inverted-image" />
      </a>
      <a href="https://github.com/kinow/" class="inline-link">
        <img src="/assets/icons/github.png" class="inverted-image" />
      </a>
    </li>
  </ul>
</div>
</div>
<div id="wrapper">
  <div id="sidebar"><div class="menu">
  <ul class="menu">
    <li class="item">
      <h1 id="kinow">KINOW</h1>
    </li>
    <li class="item">
      <a href="/" class="">About</a>
    </li>
    <li class="item">
      <a href="/blog/" class="current">Blog</a>
    </li>
    <li class="item">
      <a href="/portfolio/" class="">Portfolio</a>
    </li>
    <li class="item social-media-item">
      <a href="https://www.instagram.com/brunokinoshita/" class="inline-link">
        <img src="/assets/icons/instagram.png" class="inverted-image" />
      </a>
      <a href="https://twitter.com/kinow/" class="inline-link">
        <img src="/assets/icons/twitter.png" class="inverted-image" />
      </a>
      <a href="https://github.com/kinow/" class="inline-link">
        <img src="/assets/icons/github.png" class="inverted-image" />
      </a>
    </li>
  </ul>
</div>
</div>
  <div id="content" class="blog">
    <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Some Linux commands I used this week</h1>
    <span class="post-meta">
      <time class="dt-published" datetime="2016-05-06T00:00:00+12:00" itemprop="datePublished">May 6, 2016
      </time>
      <span>&mdash; star date: -306571.04.</span>
      <span>
        Number of words: 553.
      </span></span>
  </header>

  <ul>
  <li><a href="#listing-latest-installed-packages-in-sles">Listing latest installed packages in SLES</a></li>
  <li><a href="#listing-packages-in-sles-and-origin-repository">Listing packages in SLES and origin repository</a></li>
  <li><a href="#grep-for-content-in-xml-tags">Grep for content in XML tags</a></li>
  <li><a href="#find-python-site-packages-directory">Find Python site packages directory</a></li>
  <li><a href="#force-no-cache-via-curl-for-a-list-of-files">Force no-cache via curl for a list of files</a></li>
  <li><a href="#find-to-which-servers-a-linux-process-is-talking-to">Find to which servers a Linux process is talking to</a></li>
</ul>


  <div class="post-content e-content" itemprop="articleBody">
    <p>These are some commands I used on Linux servers this week. Adding them here in case someone else
find them interesting, and also due to my bad memory :-)</p>

<h2 id="listing-latest-installed-packages-in-sles">Listing latest installed packages in SLES</h2>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rpm <span class="nt">-qa</span> <span class="nt">--last</span>
</code></pre></div></div>

<p>This will display the last packages installed. Useful when there are packages being updated, and you
need to confirm what changed, and when.</p>

<h2 id="listing-packages-in-sles-and-origin-repository">Listing packages in SLES and origin repository</h2>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rpm <span class="nt">-qa</span> <span class="nt">--qf</span> <span class="s1">'%-30{DISTRIBUTION} %{NAME}\n'</span>| <span class="nb">sort</span>
</code></pre></div></div>

<p>The output will have two columns. The first containing the repository name, and the second column with
the package name. For example.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>devel:languages:R:base / SLE_11_SP2 R-base
devel:languages:R:base / SLE_11_SP2 R-base-devel
home:flacco:sles / SLE_11_SP3 php53-phar
home:happenpappen / SLE_11_SP2 nodejs
</code></pre></div></div>

<h2 id="grep-for-content-in-xml-tags">Grep for content in XML tags</h2>

<p>Be it for web services, or for finding things in Jenkins XML files. Being able to grep the tag attribute
or tag name might be useful. Look at the following example that uses the 
<a href="https://msdn.microsoft.com/en-us/library/ms762271%28v=vs.85%29.aspx">books XML provided by Microsoft for testing</a>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">grep</span> <span class="nt">-oP</span> <span class="s2">"(?&lt;=&lt;genre&gt;).*?(?=&lt;/genre&gt;)"</span> books.xml | <span class="nb">sort</span> | <span class="nb">uniq</span>
</code></pre></div></div>

<p>Which will outputs the following.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Computer
Fantasy
Horror
Romance
Science Fiction
</code></pre></div></div>

<h2 id="find-python-site-packages-directory">Find Python site packages directory</h2>

<p>Sometimes you have Anaconda, but also the system installation, and maybe even other Python distributions.
Knowing where Python is looking for site packages can be helpful to confirm the package exists, and also
to inspect its sources.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python <span class="nt">-c</span> <span class="s2">"from distutils.sysconfig import get_python_lib; print(get_python_lib())"</span>
</code></pre></div></div>

<p>An example of the output of the script.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/usr/lib/python2.7/dist-packages
</code></pre></div></div>

<h2 id="force-no-cache-via-curl-for-a-list-of-files">Force no-cache via curl for a list of files</h2>

<p>Useful when you have a proxy like squid caching some requests from an application and you
want to flush the cache and get the latest content (which will be cached again, but then
you can fix it once confirmed).</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">--silent</span> <span class="nt">-H</span> <span class="s1">'Cache-Control: no-cache'</span> http://systemcachingvalues.local/somedoc.html
</code></pre></div></div>

<h2 id="find-to-which-servers-a-linux-process-is-talking-to">Find to which servers a Linux process is talking to</h2>

<p>You have to find the pid of the process that you would like to investigate (e.g. 6364) and have
<a href="http://linux.die.net/man/1/strace">strace</a> installed.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>strace <span class="nt">-p</span> 6364 <span class="nt">-f</span> <span class="nt">-e</span> <span class="nv">trace</span><span class="o">=</span>network <span class="nt">-o</span> output.txt
</code></pre></div></div>

<p>The command above creates output.txt with the trace information. Then you can grep for
the IP addresses with the following regex.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">grep</span> <span class="nt">-E</span> <span class="nt">-o</span> <span class="s2">"(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)</span><span class="se">\.</span><span class="s2">(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)</span><span class="se">\.</span><span class="s2">(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)</span><span class="se">\.</span><span class="s2">(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)"</span> output.txt
</code></pre></div></div>

<p>Which will output something similar to the following example.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>127.0.1.1
127.0.1.1
127.0.1.1
192.168.20.4
10.10.0.12
...
</code></pre></div></div>

<p>And finally, you can call dig to get the server name, and also remove duplicates.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">grep</span> <span class="nt">-E</span> <span class="nt">-o</span> <span class="s2">"(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)</span><span class="se">\.</span><span class="s2">(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)</span><span class="se">\.</span><span class="s2">(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)</span><span class="se">\.</span><span class="s2">(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)"</span> output.txt | xargs <span class="nt">-l</span> dig +noall +answer +nocmd <span class="nt">-x</span> | <span class="nb">awk</span> <span class="s1">'{ print $5}'</span> | <span class="nb">sort</span> | <span class="nb">uniq</span>
</code></pre></div></div>

<p>Which gives you the following.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ec2-52-13-43-205.compute-1.amazonaws.com.
ec2-52-32-244-147.compute-1.amazonaws.com.
ec2-52-44-11-85.compute-1.amazonaws.com.
ec2-52-55-36-20.us-west-2.compute.amazonaws.com.
ec2-52-11-19-24.us-west-2.compute.amazonaws.com.
ec2-52-2-21-13.compute-1.amazonaws.com.
ec2-54-33-249-49.us-west-2.compute.amazonaws.com.
ec2-54-180-165-17.us-west-2.compute.amazonaws.com.
ec2-54-2-177-91.compute-1.amazonaws.com.
ec2-54-8-163-15.compute-1.amazonaws.com.
syd11s01-in-f124.1e110.net.
syd11s02-in-f5.1e110.net.
syd12s02-in-f3.1e110.net.
...
</code></pre></div></div>

<p>That’s all for today.</p>

<p>Happy hacking!</p>

  </div>

  <div class="tags"><p>Tags:&nbsp;<a class="label" href="/tags#linux">linux</a>.<br/></p></div>

  <a class="u-url" href="/2016/05/06/some-linux-commands-i-used-this-week.html" hidden></a>
</article>

  </div>
</div>
</body>
</html>
